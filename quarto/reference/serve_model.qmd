# serve_model { #deploy.nodes.serve_model }

`nodes.serve_model(current_run_id)`

Serves a machine learning model using MLflow in a Windows environment.

This function starts a background MLflow model serving instance for the specified run ID. 
The server runs on port 8001 and logs output to a file named `mlflow_log.txt`.

Args:
    current_run_id (dict): A dictionary containing the `run_id` of the MLflow model to be served.
        Example: {"run_id": "123456789abcdef"}

Notes:
    - This function is intended for use on Windows systems only.
    - The `mlflow` command-line interface must be installed and accessible in the system's PATH.
    - The server runs without using a conda environment (`--no-conda`).

Output:
    - Logs from the MLflow server are written to `mlflow_log.txt`.
    - A message "Serve instance running" is printed to indicate successful initiation.